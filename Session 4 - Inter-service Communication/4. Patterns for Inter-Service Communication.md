# Patterns for Inter-Service Communication

## Synchronous Microservice Communication Patterns

### 1. **Direct Service-to-Service Call**

In this pattern, one microservice directly calls another microservice over the network using a synchronous communication mechanism. Typically, HTTP or gRPC is used for these calls.

**Example:**

```java
// ProductServiceClient.java - Service that calls another microservice
@Component
public class ProductServiceClient {
    private final RestTemplate restTemplate;

    public ProductServiceClient(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    public Product getProductById(String productId) {
        // Synchronously calling another microservice
        return restTemplate.getForObject("http://inventory-service/products/" + productId, Product.class);
    }
}

// OrderService.java - Service using the client
@Service
public class OrderService {
    private final ProductServiceClient productServiceClient;

    public OrderService(ProductServiceClient productServiceClient) {
        this.productServiceClient = productServiceClient;
    }

    public Order createOrder(String productId) {
        Product product = productServiceClient.getProductById(productId);
        // Logic to create an order
        return new Order(product);
    }
}
```

**Explanation:**  
In this example, the `OrderService` calls `ProductServiceClient` to fetch product details synchronously before creating an order. The `ProductServiceClient` uses `RestTemplate` to make a direct HTTP call to the `inventory-service`.

**Trade-offs:**

*Pros:*  
- **Simplicity:** Easy to implement and understand.
- **Immediate Feedback:** The caller gets an immediate response, which is useful when an immediate action is required.

*Cons:*  
- **Tight Coupling:** Increases coupling between services, as both need to be available simultaneously.
- **Scalability Issues:** The caller might get overwhelmed if the callee service takes too long or is under heavy load.
- **Failure Propagation:** A failure in one service can propagate to others, causing cascading failures.

### 2. **Client-Side Load Balancing**

In this pattern, the client service is responsible for distributing requests across multiple instances of a target service, often using a client-side library like Netflix Ribbon or Spring Cloud LoadBalancer.

**Example:**

```java
// ProductServiceClient.java - Client with load balancing
@Component
public class ProductServiceClient {
    private final RestTemplate restTemplate;

    public ProductServiceClient(RestTemplateBuilder restTemplateBuilder) {
        this.restTemplate = restTemplateBuilder
            .rootUri("http://inventory-service")
            .build();
    }

    public Product getProductById(String productId) {
        // Load-balanced call to the service
        return restTemplate.getForObject("/products/" + productId, Product.class);
    }
}

// Application.java - Configuring RestTemplate with load balancing
@SpringBootApplication
public class Application {
    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

**Explanation:**  
`ProductServiceClient` uses a load-balanced `RestTemplate` to distribute requests across multiple instances of the `inventory-service`. The `@LoadBalanced` annotation enables client-side load balancing, allowing dynamic discovery and failover.

**Trade-offs:**

*Pros:*  
- **Improved Resilience:** Reduces the risk of a single point of failure by distributing requests across multiple instances.
- **Better Performance:** Enables dynamic load distribution, which can improve response times.

*Cons:*  
- **Additional Complexity:** Requires extra configuration and management of client-side load balancer libraries.
- **Network Overhead:** Introduces additional network latency due to the load-balancing logic.

### 3. **Circuit Breaker Pattern**

The Circuit Breaker pattern prevents a service from making requests to another service when it's likely to fail. When a failure threshold is reached, the circuit "opens" and subsequent calls are blocked for a set period, allowing the failing service to recover.

**Example:**

```java
// ProductServiceClient.java - Client with Circuit Breaker
@Component
public class ProductServiceClient {
    private final RestTemplate restTemplate;

    public ProductServiceClient(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    @CircuitBreaker(name = "productService", fallbackMethod = "fallbackProduct")
    public Product getProductById(String productId) {
        return restTemplate.getForObject("http://inventory-service/products/" + productId, Product.class);
    }

    // Fallback method when circuit is open
    public Product fallbackProduct(String productId, Throwable throwable) {
        // Handle failure scenario, return default product or cached data
        return new Product(productId, "Default Product");
    }
}

// Application.java - Configuring Resilience4j Circuit Breaker
@SpringBootApplication
@EnableCircuitBreaker
public class Application {
    @Bean
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

**Explanation:**  
In this example, `ProductServiceClient` uses a circuit breaker around the `getProductById` method. If the `inventory-service` is down or failing, the circuit breaker opens, and the `fallbackProduct` method provides an alternative response.

**Trade-offs:**

*Pros:*  
- **Failure Isolation:** Prevents cascading failures across multiple services.
- **Resilience:** Helps services recover by avoiding repeated failures during downtime.

*Cons:*  
- **Increased Complexity:** Adds more logic to handle circuit states (open, half-open, closed).
- **Potential Latency:** The fallback mechanism may introduce additional latency if not properly configured.

### 4. **Service Mesh with Sidecar Proxy**

A service mesh provides service-to-service communication, security, and observability without requiring changes to the application code. The sidecar proxy pattern involves deploying a proxy alongside each service instance to handle communication, load balancing, and security concerns.

**Example:**

*Configuration example using Istio or Linkerd:*

```yaml
# Example Istio configuration for a sidecar proxy
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: product-service
spec:
  host: inventory-service
  trafficPolicy:
    connectionPool:
      http:
        http1MaxPendingRequests: 1000
      tcp:
        maxConnections: 1000
```

**Explanation:**  
The sidecar proxy is deployed alongside each service instance, intercepting and managing all service-to-service traffic. It provides features like automatic retries, circuit breaking, and load balancing. The configuration file defines traffic rules for the service mesh.

**Trade-offs:**

*Pros:*  
- **Standardized Communication:** Provides consistent policies across services for retries, timeouts, and circuit breaking.
- **Enhanced Security:** Offers features like mTLS encryption between services.
- **Improved Observability:** Enables monitoring, logging, and tracing without modifying the application code.

*Cons:*  
- **Operational Overhead:** Requires deploying and managing additional components (e.g., sidecar proxies).
- **Resource Consumption:** Can increase resource usage due to additional proxies running alongside each service.
- **Learning Curve:** Requires knowledge of service mesh tools and configuration.

### 5. **Service Discovery**

Service Discovery allows microservices to find and communicate with each other dynamically without hard-coding service locations. It can be client-side (services query a registry to locate other services) or server-side (a load balancer queries the registry and forwards requests).

**Example:**

```java
// Using Spring Cloud Netflix Eureka
@SpringBootApplication
@EnableEurekaClient
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}

// application.properties configuration
eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/
```

**Explanation:**  
`Service Discovery` is enabled using Spring Cloud Eureka. Microservices register themselves with the Eureka server, and clients can discover other registered services dynamically.

**Trade-offs:**

*Pros:*  
- **Dynamic Scaling:** Supports dynamic addition or removal of service instances.
- **Improved Fault Tolerance:** Clients always have an updated list of healthy services.

*Cons:*  
- **Single Point of Failure:** If the discovery server fails, services can't find each other unless there's redundancy.
- **Complexity:** Adds another infrastructure component (service registry) to manage.

### 6. **API Gateway Pattern**

The API Gateway pattern is used to provide a single entry point for client requests, routing them to the appropriate microservices. It acts as an intermediary that handles request routing, authentication, rate limiting, and other cross-cutting concerns.

**Example:**

```yaml
# Sample API Gateway configuration using Spring Cloud Gateway
spring:
  cloud:
    gateway:
      routes:
        - id: product-service
          uri: http://inventory-service
          predicates:
            - Path=/products/**
        - id: order-service
          uri: http://order-service
          predicates:
            - Path=/orders/**
```

**Explanation:**  
In this example, the API Gateway routes client requests to the appropriate microservice based on the request path. Requests starting with `/products/` are routed to `inventory-service`, while `/orders/` requests go to `order-service`. 

**Trade-offs:**

*Pros:*  
- **Centralized Management:** Provides a single point to manage security, rate limiting, and monitoring.
- **Simplifies Client Code:** Clients interact with a single endpoint, abstracting the complexity of multiple microservices.
- **Cross-Cutting Concerns:** Handles cross-cutting concerns like logging, metrics, and authentication centrally.

*Cons:*  
- **Single Point of Failure:** The gateway itself can become a single point of failure.
- **Potential Bottleneck:** Can become a performance bottleneck if not properly managed or scaled.
- **Increased Latency:** Adds an additional hop to all client requests.

### 7. **Server-Side Load Balancing**

Server-side load balancing distributes incoming requests across multiple instances of a microservice, typically using a reverse proxy or load balancer like NGINX, HAProxy, or AWS Elastic Load Balancing.

**Example:**

*Configuration example using NGINX:*

```nginx
# nginx.conf - Server-side load balancer for inventory-service
http {
  upstream inventory_service {
    server inventory-service-1:8080;
    server inventory-service-2:8080;
    server inventory-service-3:8080;
  }

  server {
    location /products/ {
      proxy_pass http://inventory_service;
    }
  }
}
```

**Explanation:**  
The NGINX configuration defines an `upstream` block for the `inventory-service`, listing three instances. Requests to `/products/` are load-balanced across these instances, distributing the traffic efficiently.

**Trade-offs:**

*Pros:*  
- **Improved Scalability:** Can efficiently handle a large number of requests by distributing them across multiple service instances.
- **Increased Resilience:** Adds redundancy; if one instance fails, the load balancer redirects traffic to healthy instances.
- **Centralized Control:** Centralized control over load balancing and routing policies.

*Cons:*  
- **Infrastructure Complexity:** Requires managing and configuring an external load balancer.
- **Additional Latency:** Can introduce latency depending on load balancer configuration and network distance.
- **Single Point of Failure:** The load balancer itself can become a single point of failure unless there is redundancy.

### 8. **Bulkhead Pattern**

The Bulkhead pattern isolates different services or components into separate "bulkheads" to prevent failures in one part of the system from cascading to others. Each bulkhead represents a separate pool of resources (like threads or connections), ensuring isolation.

**Example:**

```java
// ProductServiceClient.java - Using Bulkhead with Resilience4j
@Component
public class ProductServiceClient {
    private final RestTemplate restTemplate;

    public ProductServiceClient(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    @Bulkhead(name = "productService", type = Bulkhead.Type.THREADPOOL)
    public Product getProductById(String productId) {
        return restTemplate.getForObject("http://inventory-service/products/" + productId, Product.class);
    }
}

// Application.java - Configuring Resilience4j Bulkhead
@SpringBootApplication
public class Application {
    @Bean
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

**Explanation:**  
`ProductServiceClient` uses a bulkhead pattern implemented with Resilience4j. The `Bulkhead` annotation limits the number of concurrent threads accessing `getProductById`. If the thread pool is exhausted, subsequent calls are rejected or queued, depending on the configuration.

**Trade-offs:**

*Pros:*  
- **Failure Isolation:** Limits the impact of a failure to a specific service or component, preventing cascading failures.
- **Increased Resilience:** Allows the rest of the system to remain functional even if one component is overwhelmed.

*Cons:*  
- **Resource Overhead:** Requires additional resource management (e.g., separate thread pools) and can lead to unused capacity.
- **Complexity:** Adds more complexity to the system design, requiring careful planning and configuration.

## Asynchronous Microservice Communication Patterns

Asynchronous communication patterns allow microservices to interact without waiting for a response immediately. These patterns help decouple services, improve system resiliency, and enhance scalability by enabling non-blocking communication between components.

### 1. **Event-Driven Architecture**

In an event-driven architecture, microservices communicate by producing and consuming events. When a microservice completes a task or detects a significant change, it emits an event to an event broker (such as Kafka, RabbitMQ, etc.). Other microservices that are interested in this event will consume it and react accordingly.

**Example:**

```java
// Example using Spring Kafka

// Event Producer Service
@Service
public class OrderService {
    private final KafkaTemplate<String, OrderEvent> kafkaTemplate;

    public OrderService(KafkaTemplate<String, OrderEvent> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void placeOrder(Order order) {
        // Business logic to place order
        OrderEvent event = new OrderEvent(order.getId(), "ORDER_PLACED");
        kafkaTemplate.send("order-events", event);  // Publish event to Kafka topic
    }
}

// Event Consumer Service
@Service
public class InventoryService {
    @KafkaListener(topics = "order-events", groupId = "inventory-group")
    public void handleOrderEvent(OrderEvent event) {
        if ("ORDER_PLACED".equals(event.getStatus())) {
            // Business logic to handle inventory adjustment
        }
    }
}
```

**Explanation:**  
- **OrderService** produces an event whenever a new order is placed and sends it to the "order-events" topic in Kafka.
- **InventoryService** consumes the "order-events" topic and reacts to the "ORDER_PLACED" event by adjusting the inventory.

**Trade-offs:**

- **Pros:**
  - Decouples services, allowing them to evolve independently.
  - Improves scalability and performance since services don't wait for synchronous responses.
  - Enhances resilience by reducing dependencies on the availability of other services.

- **Cons:**
  - Increased complexity in managing and monitoring events.
  - Possible event ordering issues.
  - Requires a robust event broker infrastructure.

### 2. **Message Queue-based Communication**
  
This pattern involves services communicating through a message queue. A producer service sends messages to a queue, where they are stored until a consumer service retrieves and processes them. This pattern is helpful for load balancing, handling bursts of traffic, and ensuring reliable delivery.

**Example:**

```java
// Example using Spring RabbitMQ

// Message Producer Service
@Service
public class NotificationService {
    private final RabbitTemplate rabbitTemplate;

    public NotificationService(RabbitTemplate rabbitTemplate) {
        this.rabbitTemplate = rabbitTemplate;
    }

    public void sendNotification(Notification notification) {
        // Business logic to create notification
        rabbitTemplate.convertAndSend("notifications-queue", notification);  // Send message to queue
    }
}

// Message Consumer Service
@Service
public class EmailService {
    @RabbitListener(queues = "notifications-queue")
    public void processNotification(Notification notification) {
        // Business logic to send email
    }
}
```

**Explanation:**  
- **NotificationService** sends messages to a "notifications-queue" in RabbitMQ whenever a new notification is created.
- **EmailService** consumes messages from the "notifications-queue" and sends an email based on the notification.

**Trade-offs:**

- **Pros:**
  - Provides guaranteed message delivery and buffering.
  - Helps in handling burst traffic and load balancing.
  - Services can be developed and deployed independently.

- **Cons:**
  - Potential latency in message processing.
  - Increased operational complexity due to message broker management.
  - Requires handling of message duplication and idempotency.

### 3. **Reactive Streams**

Reactive Streams provide a mechanism for asynchronous, non-blocking data streams with backpressure, ensuring that data producers do not overwhelm data consumers. This is especially useful in systems where data is continuously produced and consumed at different rates.

**Example:**

```java
// Example using Spring WebFlux

// Reactive Publisher Service
@RestController
public class PriceStreamController {
    private final FluxProcessor<PriceUpdate, PriceUpdate> processor = DirectProcessor.create();

    @GetMapping(value = "/price-stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<PriceUpdate> streamPrices() {
        return processor;  // Return the stream of price updates
    }

    public void publishPriceUpdate(PriceUpdate update) {
        processor.onNext(update);  // Publish new price updates to subscribers
    }
}

// Reactive Subscriber Service
@Service
public class PriceSubscriber {
    private final WebClient webClient = WebClient.create();

    public void subscribeToPriceStream() {
        webClient.get().uri("http://localhost:8080/price-stream")
                .retrieve()
                .bodyToFlux(PriceUpdate.class)
                .subscribe(this::handlePriceUpdate);
    }

    private void handlePriceUpdate(PriceUpdate update) {
        // Business logic to handle price update
    }
}
```

**Explanation:**  
- **PriceStreamController** exposes a `/price-stream` endpoint, providing a continuous stream of price updates to any subscribing client.
- **PriceSubscriber** uses WebClient to subscribe to the `/price-stream` and handle updates as they arrive.

**Trade-offs:**

- **Pros:**
  - Supports real-time data processing with backpressure.
  - Reduces resource consumption by avoiding blocking.
  - Improves responsiveness and scalability.

- **Cons:**
  - Steeper learning curve due to the reactive paradigm.
  - Debugging and tracing can be challenging.
  - Requires careful management of backpressure and resource allocation.

### 4. **Saga Pattern**
 
The Saga pattern is used to manage distributed transactions in a microservices architecture. A saga is a sequence of local transactions where each transaction updates data within a single service. If a step fails, the saga executes compensating transactions to undo the changes.

**Example:**

```java
// Example using Spring Boot with a Choreography-based Saga

// Order Service
@Service
public class OrderService {
    private final KafkaTemplate<String, OrderEvent> kafkaTemplate;

    public void createOrder(Order order) {
        // Local transaction: save order to the database
        // Publish order created event
        kafkaTemplate.send("order-events", new OrderEvent(order.getId(), "ORDER_CREATED"));
    }

    @KafkaListener(topics = "order-compensation-events")
    public void handleCompensation(OrderCompensationEvent event) {
        if ("ORDER_FAILED".equals(event.getStatus())) {
            // Compensating transaction: rollback order
        }
    }
}

// Payment Service
@Service
public class PaymentService {
    private final KafkaTemplate<String, PaymentEvent> kafkaTemplate;

    @KafkaListener(topics = "order-events")
    public void processPayment(OrderEvent event) {
        // Local transaction: process payment
        if (paymentSuccessful) {
            kafkaTemplate.send("payment-events", new PaymentEvent(event.getOrderId(), "PAYMENT_COMPLETED"));
        } else {
            kafkaTemplate.send("order-compensation-events", new OrderCompensationEvent(event.getOrderId(), "ORDER_FAILED"));
        }
    }
}
```

**Explanation:**  
- **OrderService** creates an order and publishes an "ORDER_CREATED" event. If a failure occurs, it listens for "ORDER_FAILED" events to perform compensation.
- **PaymentService** listens for "ORDER_CREATED" events, processes the payment, and sends a success or failure event to trigger compensation if needed.

**Trade-offs:**

- **Pros:**
  - Provides a way to handle distributed transactions across microservices.
  - Increases resilience by allowing partial failures to be handled gracefully.
  - Decouples services by managing transactions through events.

- **Cons:**
  - Increased complexity in handling compensating transactions.
  - Potential inconsistency during the saga execution until all transactions are completed.
  - Requires robust monitoring and event handling.

### 5. **CQRS (Command Query Responsibility Segregation) Pattern**

CQRS separates the read and write operations for a data store, using different models for updating (commands) and querying (queries). This pattern helps optimize performance, scalability, and security in systems where read and write workloads are different.

**Example:**

```java
// Example using Spring Boot with CQRS

// Command Handler
@Service
public class OrderCommandService {
    private final OrderRepository orderRepository;

    public Order createOrder(CreateOrderCommand command) {
        // Handle command: create order in write database
        Order order = new Order(command.getProductId(), command.getQuantity());
        return orderRepository.save(order);
    }
}

// Query Handler
@Service
public class OrderQueryService {
    private final OrderViewRepository orderViewRepository;

    public OrderView getOrderById(String orderId) {
        // Handle query: fetch order details from read database
        return orderViewRepository.findById(orderId).orElseThrow(OrderNotFoundException::new);
    }
}
```

**Explanation:**  
- **OrderCommandService** handles commands to update data, such as creating orders in the write database.
- **OrderQueryService** handles queries to fetch data, such as retrieving order details from a separate read database.

**Trade-offs:**

- **Pros:**
  - Optimizes read and write performance by separating concerns.
  - Supports scalability by independently scaling the read and write sides.
  - Enhances security by applying different authorization rules for commands and queries.

- **Cons:**
  - Complexity increases due to maintaining two models and synchronization between them.
  - Eventual consistency issues may arise between read and write models.
  - Requires more storage and infrastructure to maintain separate data stores.

### 6. **Polling Pattern**
  
In the Polling pattern, a service periodically checks (polls) another service or data source for updates. This pattern is useful when a service does not support event-driven communication or when updates are needed at regular intervals.

**Example:**

```java
// Example using Spring Scheduling

// Polling Service
@Service
public class InventoryPollingService {
    private final RestTemplate restTemplate;
    private final InventoryRepository inventoryRepository;

    @Scheduled(fixedRate = 5000) // Poll every 5 seconds
    public void pollInventoryUpdates() {
        ResponseEntity<List<InventoryUpdate>> response = restTemplate.exchange(
            "http://inventory-service/updates",
            HttpMethod.GET,
            null,
            new ParameterizedTypeReference<List<InventoryUpdate>>() {}
        );
        if (response.getStatusCode().is2xxSuccessful()) {
            List<InventoryUpdate> updates = response.getBody();
            updates.forEach(inventoryRepository::save); // Save updates to the local database
        }
    }
}
```

**Explanation:**  
- **InventoryPollingService** uses a scheduled task to poll the inventory service for updates every 5 seconds and processes the updates locally.

**Trade-offs:**

- **Pros:**
  - Simple to implement, especially when the other service doesn't support events.
  - Allows control over the frequency of checks and network usage.

- **Cons:**
  - Can lead to unnecessary network traffic and increased latency.
  - Inefficient compared to event-driven approaches for real-time updates.
  - Difficult to scale for large volumes of data.

### 7. **Dead Letter Queue (DLQ) Pattern**
 
A Dead Letter Queue (DLQ) is a secondary queue that receives messages that could not be processed successfully by the primary queue. It is used to handle message failures, prevent message loss, and allow for manual inspection and reprocessing of failed messages.

**Example:**

```java
// Example using Spring RabbitMQ with Dead Letter Queue

// Configuration for DLQ
@Configuration
public class RabbitMQConfig {
    @Bean
    public Queue primaryQueue() {
        return QueueBuilder.durable("primary-queue")
            .withArgument("x-dead-letter-exchange", "dlx") // DLX configuration
            .withArgument("x-dead-letter-routing-key", "dead-letter-queue")
            .build();
    }

    @Bean
    public Queue deadLetterQueue() {
        return QueueBuilder.durable("dead-letter-queue").build();
    }
}

// Message Listener with DLQ Handling
@Service
public class MessageListenerService {
    @RabbitListener(queues = "primary-queue")
    public void handleMessage(String message) {
        try {
            // Business logic to process message
        } catch (Exception e) {
            // Handling failed message
            throw new AmqpRejectAndDontRequeueException("Message processing failed"); // Sends to DLQ
        }
    }
}
```

**Explanation:**  
- **RabbitMQConfig** sets up a primary queue with a dead-letter exchange (DLX) and a dead-letter queue (DLQ) for handling failed messages.
- **MessageListenerService** processes messages and, in case of an exception, rejects and sends them to the DLQ.

**Trade-offs:**

- **Pros:**
  - Prevents message loss and allows for recovery of failed messages.
  - Facilitates monitoring and analysis of failed messages.
  - Enhances system reliability by isolating problematic messages.

- **Cons:**
  - Adds operational complexity for managing DLQs.
  - Requires careful handling to avoid repeated failures.
  - Can lead to storage and performance overhead if not managed properly.